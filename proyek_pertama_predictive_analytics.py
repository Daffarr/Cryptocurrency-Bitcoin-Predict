# -*- coding: utf-8 -*-
"""Proyek Pertama Predictive Analytics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PN7hDWXBWFgpBFKMMZKPbQ5q0-6IrxMZ

## DATA DIRI
2. Nama = DAFFA RAYHAN RIADI
3. Username = daffarayhanriadi
4. Email = daffarayhanriadi@gmail.com 
5. No. Telepon = +6285277116302
6. Kota Domisili = Purwokerto
7. Tempat Lahir = Kota Padangsidempuan - Sumatera Utara
8. Tanggal Lahir = 03 Oktober 2022
9. Jenis Kelamin = Laki-laki
10. Pendidikan Terakhir = SMA
11. Pekerjaan/Profesi saat ini = Pelajar/Mahasiswa
12. Perusahaan/Institusi saat ini = Institut Teknologi Telkom Purwokerto

## Import Library
Melakukan import beberapa library yang diperlukan
"""

# Commented out IPython magic to ensure Python compatibility.
# import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns

from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, MinMaxScaler

# from sklearn.pipeline import Pipeline
# from sklearn.linear_model import LogisticRegression
# from sklearn.tree import DecisionTreeClassifier
# from sklearn.ensemble import GradientBoostingClassifier
# from sklearn.ensemble import RandomForestClassifier
# from sklearn.neighbors import KNeighborsClassifier 

# from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
# from sklearn import metrics
# from sklearn.metrics import roc_curve, auc, roc_auc_score

from sklearn.decomposition import PCA
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

"""# Data Loading
Melakukan Data Loading dengan [Dataset](https://www.kaggle.com/datasets/sudalairajkumar/cryptocurrencypricehistory?select=coin_Bitcoin.csv) berikut ini.
"""

url_dataset = 'https://raw.githubusercontent.com/Daffarr/proyek1MLTerapan/main/Dataset/coin_Bitcoin.csv'
df_bitcoin = pd.read_csv(url_dataset)
df_bitcoin

"""# Exploratory Data

###Variabel-variabel pada dataset adalah sebagai berikut:
* SNo: Nomor Seri atau Nomor Baris Pada Dataset
* Name: Nama mata uang kripto
* Symbol: Simbol mata uang kripto
* Date: Tanggal pencatatan data
* High : Harga tertinggi pada hari tertentu
* Low : Harga terendah pada hari tertentu
* Open : Harga pembukaan pada hari tertentu
* Close : Harga penutupan pada hari tertentu
* Volume : Volume transaksi pada hari tertentu
* Mastercap : Kapitalisasi pasar dalam USD

Pada kali ini fitur yang akan menjadi target kita adalah Close

# Mengecek Informasi Data
"""

df_bitcoin.info()

"""# Informasi Statistik dari Data
Data di bawah memiliki beberapa informasi statistik pada masing-masing kolom, antara lain:

* count adalah jumlah sampel pada data.
* mean adalah nilai rata-rata.
* std adalah standar deviasi.
* min yaitu nilai minimum setiap kolom.
* 25% adalah kuartil pertama. Kuartil adalah nilai yang menandai batas interval dalam empat bagian sebaran yang sama.
* 50% adalah kuartil kedua, atau biasa juga disebut median (nilai tengah).
* 75% adalah kuartil ketiga.
* Max adalah nilai maksimum
"""

df_bitcoin.describe()

"""## Melihat data yang memiliki nilai 0 pada sample Data"""

a = (df_bitcoin.SNo == 0).sum()
b = (df_bitcoin.High == 0).sum()
c = (df_bitcoin.Low == 0).sum()
e = (df_bitcoin.Open == 0).sum()
f = (df_bitcoin.Close == 0).sum()
g = (df_bitcoin.Volume == 0).sum()
h = (df_bitcoin.Marketcap == 0).sum()


print("Nilai 0 di kolom SNo ada: ", a)
print("Nilai 0 di kolom High ada: ", b)
print("Nilai 0 di kolom Low ada: ", c)
print("Nilai 0 di kolom Open ada: ", e)
print("Nilai 0 di kolom Close ada: ", f)
print("Nilai 0 di kolom Volume ada: ", g)
print("Nilai 0 di kolom Marketcap ada: ", h)

"""## Melihat data yang memiliki nilai null pada sample Data"""

df_bitcoin.isnull().sum()

"""## Melihat banyak baris dan kolom pada Dataset"""

df_bitcoin.shape

"""## Mengecek Data Yang Termasuk Dalam Outlier"""

sns.boxplot(x=df_bitcoin['High'])

sns.boxplot(x=df_bitcoin['Low'])

sns.boxplot(x=df_bitcoin['Open'])

sns.boxplot(x=df_bitcoin['Close'])

sns.boxplot(x=df_bitcoin['Volume'])

sns.boxplot(x=df_bitcoin['Marketcap'])

"""### IQR Method
Dapat dilihat pada visualisasi diatas dataset ini memiliki data outlier yang cukup banyak, maka untuk menghandle data outlier tersebut pada dataset ini akan menggunakan IQR Method yaitu dengan menghapus data yang berada diluar interquartile range.
"""

Q1 = df_bitcoin.quantile(.25)
Q3 = df_bitcoin.quantile(.75)
IQR = Q3 - Q1

df_bitcoin = df_bitcoin[~((df_bitcoin < Q1 - 1.5 * IQR) | (df_bitcoin > Q3 + 1.5 * IQR)).any(axis=1)]

# Cek dataset setelah menghapus / drop data yang termasuk dalam outlier
df_bitcoin.shape

"""Mengecek visualisasi data outlier kembali, apakah sudah terhapus atau belum, dan dapat dilihat pada visualisasi dibawah ini, dataset masih memiliki data outlier. Data outlier disini tidak akan dihapus dengan asumsi agar tidak menghilangkan keberagaman dari sample data."""

sns.boxplot(x=df_bitcoin['High'])

"""# Univariate Analysis

Kesimpulan yang menurut saya bisa dapat dilihat disini adalah kenaikan harga dari kripto bitcoin sebanding dengan penurunan sampel data.
"""

# Numerical features
hist_plot = df_bitcoin.hist(figsize=(20,15))

"""# Multivariate Analysis

##### Melalui Visualisasi dibawah ini dapat kita lihat bahwa fitur close memiliki korelasi yang tinggi atau baik dengan beberapa fitur yang ada, yakni High, Low, Open dan Marketcap. Sedangkan fitur volume dapat kita lihat memiliki korelasi yang cukup rendah.
"""

sns.pairplot(df_bitcoin, diag_kind = 'kde')
plt.show()

"""Disini dapat kita lihat secara detail korelasinya nya menggunakan angka, dapat kita lihat rata-rata korelasi yang ada dari fitur Close dengan fitur lain seperti High, Low, Open dan Marketcap itu mencapai angka 0.81, sedangkan volume mencapai angka 0.78, oleh karena itu dapat memungkinkan kita untuk menghapus fitur volume pada dataset ini."""

# Untuk mengevaluasi skor korelasinya, gunakan fungsi corr().
plt.figure(figsize=(12, 10))
correlation_matrix = df_bitcoin.corr().round(2)

# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""## Data Preparation

### Menghapus Data Yang Tidak Diperlukan
Kolom data **Volume** dihapus karena memiliki korelasi yang rendah. Kemudian Kolom data seperti **(SNo, Name, Symbol, Date, Marketcap)** tidak diperlukan untuk pelatihan, karena data tersebut akan mengganggu model dalam mempelajari data. Karena isi dari data tersebut tidak memiliki value yang berarti untuk dipelajari oleh model.
"""

df_bitcoin.drop(['SNo', 'Name', 'Symbol','Date','Marketcap', 'Volume'], axis = 1, inplace = True)
df_bitcoin

"""### Split dataset

Membagi dataset menjadi data latih (x_train & y_train) dan data uji (x_test & y_test)
"""

x = df_bitcoin.drop(['Close'], axis=1).values
y = df_bitcoin['Close'].values

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)

print(len(x))
print(len(x_train))
print(len(x_test))

"""### Normalization Dataset
Melakukan transformasi pada data fitur fitur yang akan dipelajari oleh model menggunakan library MinMaxScaler ataupun StandardScaler. Setelah dibandingkan library MinMaxScaler memiliki akurasi sedikit lebih baik, sehingga pada kali ini menggunakan library tersebut.
"""

# scaler = StandardScaler()
# x_train = scaler.fit_transform(x_train)
# x_train

scaler = MinMaxScaler()
x_train = scaler.fit_transform(x_train)
x_train

# features=['High', 'Low', 'Open', 'Close']

"""## MODEL SELECTION
### Tuning Hyperparameters

Melakukan tuning hyperparameters untuk mendapatkan parameter dengan performa terbaik pada model.
"""

models = pd.DataFrame(columns=['train_mse', 'test_mse'],
                      index=['KNN', 'RandomForestRegression', 'SVR'])

# Menggunakan Model Algoritma Support Vector Regression (SVR)
svr_model = SVR()
parameters = {
    'kernel': ['rbf'],
    'C':     [1000, 10000, 100000],
    'gamma': [0.3, 0.03, 0.003]
}

svr_model_search = GridSearchCV(
    svr_model, 
    parameters,
    cv=5, 
    verbose=1,
    n_jobs=6,
)

svr_model_search.fit(x_train, y_train)
svr_model_best_params = svr_model_search.best_params_

# Menggunakan Algoritma K-Neighbors Regression (KNN)
knn_model = KNeighborsRegressor()
parameters =  {
    'n_neighbors': range(1, 25),
}

knn_model_search = GridSearchCV(
  knn_model, 
  parameters, 
  cv=5,
  verbose=1, 
  n_jobs=6,
)

knn_model_search.fit(x_train, y_train)
knn_model_best_params = knn_model_search.best_params_

# Menggunakan Model Algoritma Random Forest Regression (RFR)
rfr_model = RandomForestRegressor()
parameters =  {
    'n_estimators': range(1, 10),
    'max_depth': [16, 32, 64],
}

rfr_model_search = GridSearchCV(
  rfr_model, 
  parameters, 
  cv=5,
  verbose=1,
  n_jobs=6,
)
rfr_model_search.fit(x_train, y_train)
rfr_model_best_params = rfr_model_search.best_params_

svr_model = SVR(
  C=svr_model_best_params["C"], 
  gamma=svr_model_best_params["gamma"], 
  kernel=svr_model_best_params['kernel']
)                          
svr_model.fit(x_train, y_train)

knn_model = KNeighborsRegressor(n_neighbors=knn_model_best_params["n_neighbors"])
knn_model.fit(x_train, y_train)

rfr_model = RandomForestRegressor(
  n_estimators=rfr_model_best_params["n_estimators"], 
  max_depth=rfr_model_best_params["max_depth"]
)
rfr_model.fit(x_train, y_train)

x_test = scaler.transform(x_test)
x_test

# Melakukan prediksi atas model yang telah dilatih
model_dict = {'KNN': knn_model, 'RandomForestRegression': rfr_model, 'SVR': svr_model}

for name, model in model_dict.items():
  models.loc[name, 'train_mse'] = mean_squared_error(
    y_true=y_train, 
    y_pred=model.predict(x_train)
  )
  models.loc[name, 'test_mse'] = mean_squared_error(
    y_true=y_test, 
    y_pred=model.predict(x_test)
  ) 

models

# Visualisasi dari prediksi yang telah dilakukan
fig, ax = plt.subplots()
models.sort_values(by='test_mse', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

test_data = x_test.copy()
predictions = {'y_true':y_test}
for name, model in model_dict.items():
  predictions['prediction_' + name] = model.predict(test_data)
 
predictions = pd.DataFrame(predictions)
predictions

predictions = predictions.tail(10)
predictions.plot(kind='bar',figsize=(16,10))
plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')
plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')
plt.show()